name: "tokenizer"

backend: "python"

max_batch_size: 512

input [
    {
        name: "input_text"
        data_type: TYPE_STRING
        dims: [ 1 ]
    }
]

output [
  {
    name: "input_ids"
    data_type: TYPE_INT64
    dims: [ -1 ]
  }
]
output [
  {
    name: "token_type_ids"
    data_type: TYPE_INT64
    dims: [ -1 ]
  }
]
output [
  {
    name: "attention_mask"
    data_type: TYPE_INT64
    dims: [ -1 ]
  }
]

output [
  {
    name: "offset_mapping"
    data_type: TYPE_INT64
    dims: [ -1, 2 ]
  }
]

instance_group [
    {
        count: 4
        kind: KIND_CPU
    }
]

parameters [
  {
    key: "model_name"
    value: { string_value: "dslim/bert-base-NER" }
  }
]
